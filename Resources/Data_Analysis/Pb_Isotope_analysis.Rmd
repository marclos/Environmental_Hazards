---
title: "Importing and Analyzing Pb Isotope and Concentration Data"
author: "Marc Los Huertos"
date: "12/3/2017"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Purpose of Document

I have written this to help you read csv file and manipulate Pb data into R. Then provide some tools in the analysis. Please do not just copy and paste commands, or you will be terribly frustrated, becuase this was not designed for that purpose. 

However, if you use this document as a "basis" for your lab report, customizing the headers, r code, and text as you go, you will have the word document that you can use as a template for your lab. 

### Work Flow suggestions

I suggest using the following work flow:

- Create a new Rmd File
- Read each section in order and adjust the text and code as you go. 
- Revise the Rmd to create a nice word document with figures while removing the R code that the reader does not need to see in the final report.
- Create a word document and edit the document to create a lab report using the report guidelines on Sakai.

## Finding the Data

First, we need to convert the excel file into comma separated values, which we can do by saving the file as a csv. This will give a few warnings, but don't worry about that.

Now you'll need to upload the data into Rstudio.

Next we need is to find the data -- the name and the directory path. With this, we can then tell R where the data reside and create an "object" that refers to the path and filename. 

I like using the **file.choose()** function, because it provides a popup window that we can use to search for the file. Use this function in the console and copy the path and file name to insert into your Rmd and create an object that references the path and filename. I have done this below for **my** file and path, yours will be different!!

```{r filename}
file = "/home/CAMPUS/mwl04747/github/Environmental_Hazards/Data/Pb_Data/171116_EA30_MLH4_revised.csv"
```

Notice that in the Rblock above the the r block as a label "filename". This helps me figure out where I am when I find a knitting problem. You can leave that blank or put in a label. If you do put in a label, they need to be unique -- repeated ones will give an error. 

## Reading Data into R

To read data into R we use **read.csv()** function

```{r readcsv}
import = read.csv(file)
```

Whenever I read data, I check to make sure the object I created is what I had expected and intended. 

### Checking the file

1. What are the variable names?

```{r}
names(import)
```

What is the structure?

2. What is the structure of the object?
```{r}
str(import)
```

A dataframe is the most common data structure in R. Notice the dollar signs -- these can be used to select specific variables within the dataframe. 


## Preparing Data for Analysis

### Tranform data mg/kg of soil

The concentration from the ICP-MS was based on the extraction concentration, so we need to divide by the soil weight and multipy by the amount of dilution solution (water and nitric acid). I have created a new variable name, "Result", so I don't get mixed up and remove the old variable name. 

```{r transform}
import$Result = 25/5*import$Concentration
drops <- c("Concentration")
import = import[ , !(names(import) %in% drops)]
```

Again, it's a good idea to check the data:

```{r checkdata}
head(import)
```

### Subset Pb Analytes

Let's subset the data -- for now, we will only look at Pb. NOTE: Lab reports that also analyze other analytes will be awarded more points.

We can subset the rows where the Analyte = Pb. Unfortunately, R's method to do this is a bit obtuse:  
```{r}
Pb_data = import[import$Analyte=="Pb",]
head(Pb_data)
```

### Remove Blank 

It turns out removing our blank is trickier than I had anticipated. we need to "Install" a library or package call *gdata*. NOTE: A report discussion about the role of the Blank and our results will be given more points.

NOTE: 12/7, I found a more robust approach to delete the blank in the levels() so that it won't show up in the boxplot!
```{r}
Pb_data = Pb_data[!Pb_data$Park=="Blank", ]
library(dplyr)
Pb_data <- Pb_data %>% filter(!Park =="Blank") %>% droplevels()
```

## Wrangle Data Format

Wrangling data is reformats the data -- moving columns into rows based on a 'key'. In our case, we need to separate the 3 isotopes so we can add them together and make a new variable, TotalPb!

To do this, I'll create a new file name. The *spread()* function is a bit complicated, so I can't go into it, but check to see how the data change!

```{r}
library(tidyr)

Pb = Pb_data %>% spread(Mass, Result)

Pb$Pb67 = round(Pb$'206'/Pb$'207',3)
Pb$Pb68 = round(Pb$'206'/Pb$'208',3)
Pb$Total = Pb$'206'+ Pb$'207'+ Pb$'208'
Pb
```


## Renaming Parks: Letters to Names! (After meeting with Ally)

```{r }
library(plyr)
Pb$Park <- revalue(Pb$Park, c("B"="Blaisdell", "C"="Chaparral"))
```


## Creating Hypotheses to Test (Modified after talking to Bebe...)

In reality, we begin with asking questions and then generating hypotheses that are actually "testable statements" that *might* answer our question. 

For example, we might ask, "are lead concentrations high?"  This is a good question, but not testable --- because we don't know what the definition of high is.  So, to operationalize this question we can ask, are the Pb concentrations above an EPA limit?  This can be turned into a testable statement (or null hypothesis): Pb concentations below XX mg/kg. I don't know what the EPA limit is for soils, but you could substitute it here.

There are numerous questions that one can ask:

Is [Pb] elevated in Claremont Parks?

- Null Hypothesis: [Pb] is not above the EPA Threshold.

Another question might be, Do the parks have different [Pb]?

- Null Hypothesis: Six Claremon Parks have the same soil [Pb].

Are the sources of Pb different at each park? Since the isotope ratio tells us something about the geological sources, we might have a testable null hypothesis: 

- The ratio between 206/207 do not differ by park

Another question worth asking is if the parks are different: Is the [Pb] different between Claremont Parks? Where the null hypothesis could be 

- [Pb] is the same for sampled parks in Claremont

Asking these questions is a good step, but just like the residents of Toms River, the "why" is just as important as the "what". Do, we need to ask some questions about why are the concentrations different? 

For example, does the distance, age of the park or management if the park influence the outcome of the result?  pH, irrigation, and age of parks might all contribute to the differences. Which hypothesis do you think is worth testing?

- Distance from freeway does not correlate with Pb

- pH does not correlate with Pb

- Soil moisture does not correlate with Pb

- Age of park does not correlate with Pb

Now your job is to capture the appropriate data and then analyze it with R. :-)

## Analyze Basic Hypothesis

Are the park [Pb] different? Our null hypothesis is that the means of each park are the same, or $\mu_1 = \mu_2$ = \mu_{...} = \mu_n$.

We can analyze this with a ANOVA (in R using *aov()*): 
```{r}
Pb.aov = aov(Total ~ Park, data=Pb)
summary(Pb.aov)

```

To visualize this we might use a boxplot:

```{r boxplot}
boxplot(Total ~ Park, data=Pb)
```

We now can make these prettier! For example, 

```{r improved}
boxplot(Total ~ Park, data=Pb, main="Some Title", xlab="x label", ylab="y label", las=1)
```

NOTE: The Park names would be better than letters! Who wants to try to remember the park names? Besides, the City or it's residents are going to be clueless on these letters!

## Do Isotope Ratios Differ by Park?

First, we need to decide what our question is. In this case, we'll ask do the sources, based on their isotope ratio differ by park. As a null hypothesis, we then need to test:

There is no difference in 206Pb/207Pb isotope ratio between parks.

Of course, it will be up to you to justify the "value" of this hypothesis based on the literature. 

```{r isotoperatiotest}
boxplot(Pb67 ~ Park, data=Pb)

Pb67.aov <- aov(Pb67 ~ Park, data=Pb)

summary(Pb67.aov)


```


## Analyze Data relative to "anthropogenic sources"

I found an value of 1.14 of a 206Pb/207Pb to suggest a gasoline source versus a coal source, but this was for Europe. Their coal probably has a different signature that US coal, so I suspect you'll need to find a better source than what I found.

The *prop.test()* is useful to evaluate if the number of "positives" exceed what might be expected by chance. So... I tried that with the value that I found in the literature for Pb isotope ratios of 1.14.

```{r}
exceed = sum(Pb$Pb67 > 1.14); exceed
prop.test(exceed, length(Pb$Pb67))
```


## Distance to Park from I10

1. Is Pb Correlated to Distance?

Null Hypothesis: There is no relationship between Distance and Pb concentrations. 

To determine the answer, you'll need to create Distances for each park. First we create a new variable: 


```{r}
Pb$Distance = NA
```

Then we start adding distances. I created a fake one below, but you'll need to create a distance for each park following my example:

```{r creatingdistances}
Pb$Distance[Pb$Park=="C"] <- 3.2
head(Pb)
```

To analyze the data, we need to rely on a regression (using *lm()* or a linear model in R). Remember, in a linear model y = f(x) or y~x, where y is dependent and x is independent. In our case, Pb is the response or dependent variable and distance is the predictor or indepenedent variable. 

```{r}
Pb.lm <- lm(Total ~ Distance, data=Pb)
summary(Pb.lm)
```

## pH and Pb -- To Be Developed if anyone asks

Null Hypothesis: There is no relationship between pH:
```{r}
#pH.lm <- lm(Pb ~ pH, data=import)
#summary(pH.lm)
```

## Ploting Best Fit Line -- To Be Developed if requested

What is r-squared?  It tells us how much of the variation in the response is explained by the predictor. 

Let's create a plot and evaluate the best fit line:

```{r}
#plot(Lead ~ Distance10Bogus, data=import)
#abline(coef(Pb.lm))
```

See the variation around the line? 

The $r^2$ can be interpreted as a percentage of the variation explained. In other words, if the value is 0.33, then 33% of the variation in y is explained by x. In environmental science, it's rare to have over 50% because there are some many confounding factors!

## Soil Moiture and Pb

Soil moisture is highly variable -- depending on rainfall and irrigation. However, if soils are constantly wet, then we might expect Pb do behave differently than when (or where) soils are wet. 

After weighing the wet soil in the tin mass (wet_soil) and dry soil in the tin mass (dry_soil) and the tin mass (tin) we can easily calculate the soil moisture content: 

$$Moisture~\% = (wet\_soil - dry\_soil)/(dry\_soil - tin)*100$$

In R that might look like $Pb\$Moisture~ <-~ (Pb\$wet\_soil - Pb\$dry\_soil)/(Pb\$dry\_soil - tin)*100$
Now if you put these numbers into your csv file and import the new file into the Rstudio directory you can see if Pb is a function of moisture, i.e. Pb = f(moisture). Since moisture is continuous variable, then we can use a linear model: *lm()*

```{r, eval=FALSE}
moisture.lm <- lm(Pb ~ Moisture, data=Pb)
summary(moisture.lm)
```

Of course, if you want to graph the data, you should *plot* the data and fit a best fit line if the trend is significant. 


